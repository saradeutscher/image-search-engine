# Image Search Engine Test Case
Very small/basic example of how the image classification done by CLIP on un-tagged/labeled images could be used to create a image-based search engine. 

Run locally with a local PostgreSQL database (an open-source object-relational database) that stores the images along with CLIP model generated vector projections of each image. Vector projections are generated by running CLIPVisionModelWithProjection over the images: see image-search-server/model.js 

Runs the text model CLIPTextModelWithProjection over the search term inputed, then compares the vector projection for the text to the vector projections generated by the vision model and stored along with the images in the database.

Returns top 5 matching images (even if none have great probabilities, or there were are more than 5 images that matched)

Adapted from: 
https://www.tigerdata.com/blog/how-to-build-an-image-search-application-with-openai-clip-postgresql-in-javascript

Website is built using React, and the react-router-template as a starting point

## Getting Started

### Installation

Install the dependencies:

```bash
npm install
```

### Development

Start the development server with HMR:

```bash
npm run dev
```

Start the server side:
```bash
node index.js
```

Your application will be available at `http://localhost:5173`.

## Code Layout
```
├── package.json
├── package-lock.json
├── image-search-server/
│   └── node_modules/    
│   └── dataset/
│   └── database.js
│   └── index.js
│   └── model.js
│   └── utils.js
│   └── package-lock.json
│   └── package.json
├── app/
│   └── routes/
│       └── home.tsx
│   └── App.jsx
│   └── SearchBar.jsx
│   └── Image.jsx
│   └── useImage.jsx
│   └── root.jsx
│   └── routes.ts
```
